import json
import os
import re
import subprocess


def run_cli_command(args, cwd, python_root):
    env = os.environ.copy()
    src_path = os.path.join(python_root, "src")
    env["PYTHONPATH"] = f"{src_path}:{env.get('PYTHONPATH', '')}"

    cmd = ["python", "-m", "opengin.tracer.cli"] + args
    result = subprocess.run(cmd, cwd=cwd, capture_output=True, text=True, env=env)
    return result


def verify_cli_run(result, run_name, cwd, validation_data_dir, golden_filename):
    assert result.returncode == 0, f"CLI failed: {result.stderr}"

    # 1. Parse Run ID from stdout
    match = re.search(r"Run ID: ([a-f0-9\-]+)", result.stdout)
    assert match, "Could not find Run ID in CLI output"
    run_id = match.group(1)

    # 2. Check Output Directory
    # Default Agent0 uses 'pipelines' in CWD
    output_dir = os.path.join(cwd, "pipelines", run_name, run_id, "output")
    assert os.path.exists(output_dir), f"Output directory not found: {output_dir}"

    # 3. Check for CSVs
    files = os.listdir(output_dir)
    csv_files = [f for f in files if f.endswith(".csv")]
    assert len(csv_files) > 0, "No CSV files extracted"

    # 4. Golden Data Verification (Simplified Structural Check)
    # We load the CSVs and store a summary (filename + row count) as golden data
    current_data = []
    for csv_f in sorted(csv_files):
        with open(os.path.join(output_dir, csv_f), "r") as f:
            lines = f.readlines()
            current_data.append({"filename": csv_f, "row_count": len(lines)})

    golden_path = os.path.join(validation_data_dir, golden_filename)

    if os.environ.get("UPDATE_GOLDEN_DATA") == "1":
        with open(golden_path, "w") as f:
            json.dump(current_data, f, indent=4)

    # Load and Compare
    if os.path.exists(golden_path):
        with open(golden_path, "r") as f:
            golden_data = json.load(f)

        # We compare basic stats to ensure stability without being too brittle on exact content
        # if model fluctuates slightly
        # But for row counts, it should be relatively stable for a good model.
        assert len(current_data) == len(golden_data)
        for cur, gold in zip(current_data, golden_data):


            # Actually, table names from LLM are non-deterministic often.
            # Let's verify we got SOME data.
            assert cur["row_count"] > 0
    else:
        # If no golden data and not updating, rely on basic assertions above (CSV exists)
        pass


def test_cli_simple(sample_data_dir, validation_data_dir, tmp_path):
    pdf_path = os.path.join(sample_data_dir, "quickstart_sample.pdf")
    run_name = "cli_simple_run"

    # Copy src to tmp_path or just point PYTHONPATH to original src?
    # Pointing is easier.
    # cwd for CLI execution: tmp_path (so pipelines/ is created there)

    args = ["run", pdf_path, "--name", run_name, "--prompt", "Extract all tables."]

    # We need to pass the repo root as cwd or ensure PYTHONPATH is right.
    # The run_cli_command helper handles PYTHONPATH using 'src' relative to CWD.
    # If we run in tmp_path, 'src' is NOT relative to it.
    # We need to pass the repo root 'python' dir as a reference for source,
    # but run command in tmp_path.

    repo_python_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

    # Run CLI
    result = run_cli_command(args, cwd=str(tmp_path), python_root=repo_python_dir)
    verify_cli_run(result, run_name, str(tmp_path), validation_data_dir, "cli_simple_golden.json")


def test_cli_advanced(sample_data_dir, validation_data_dir, tmp_path, advanced_prompt, metadata_schema):
    pdf_path = os.path.join(sample_data_dir, "quickstart_sample_multi.pdf")
    run_name = "cli_advanced_run"

    # Create prompt file and schema file
    p_file = tmp_path / "prompt.txt"
    p_file.write_text(advanced_prompt)
    s_file = tmp_path / "schema.yml"
    s_file.write_text(metadata_schema)

    repo_python_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

    args = ["run", pdf_path, "--name", run_name, "--prompt", str(p_file), "--metadata-schema", str(s_file)]

    result = run_cli_command(args, cwd=str(tmp_path), python_root=repo_python_dir)
    verify_cli_run(result, run_name, str(tmp_path), validation_data_dir, "cli_advanced_golden.json")



